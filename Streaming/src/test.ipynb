{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5b0b7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_create_producer error: NoBrokersAvailable, retry 1/6 in 1.0s\n",
      "_create_producer error: NoBrokersAvailable, retry 2/6 in 2.0s\n",
      "_create_producer error: NoBrokersAvailable, retry 3/6 in 4.0s\n",
      "_create_producer error: NoBrokersAvailable, retry 4/6 in 8.0s\n",
      "_create_producer error: NoBrokersAvailable, retry 5/6 in 16.0s\n",
      "_create_producer error: NoBrokersAvailable, retry 6/6 in 30.0s\n",
      "_create_producer failed after 7 attempts: NoBrokersAvailable\n"
     ]
    },
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hs/qgyqqppj281bp7zh9vj3jry40000gn/T/ipykernel_56366/2623394441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKafkaDataProducerService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTOPIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBROKER_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtickers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tickers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hs/qgyqqppj281bp7zh9vj3jry40000gn/T/ipykernel_56366/2623394441.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, topic, brokers, retries)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     @retry_with_backoff(max_retries = int(os.getenv(\"RETRY_MAX\", 6)), \n",
      "\u001b[0;32m/var/folders/hs/qgyqqppj281bp7zh9vj3jry40000gn/T/ipykernel_56366/2623394441.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mretries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/hs/qgyqqppj281bp7zh9vj3jry40000gn/T/ipykernel_56366/2623394441.py\u001b[0m in \u001b[0;36m_create_producer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m                         max_backoff = float(os.getenv(\"RETRY_MAX_BACKOFF\", 30.0)))\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mKafkaProducer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         return KafkaProducer(\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mbootstrap_servers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrokers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mretries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/kafka/producer/kafka.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         client = KafkaClient(metrics=self._metrics, metric_group_prefix='producer',\n\u001b[0m\u001b[1;32m    382\u001b[0m                              \u001b[0mwakeup_timeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_block_ms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                              **self.config)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/kafka/client_async.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mcheck_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version_auto_timeout_ms'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_can_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/kafka/client_async.py\u001b[0m in \u001b[0;36mcheck_version\u001b[0;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoBrokersAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "from client import Api\n",
    "from kafka import KafkaProducer\n",
    "from json import dumps\n",
    "import json\n",
    "from kafka.errors import KafkaError\n",
    "import functools\n",
    "import time\n",
    "import os\n",
    "\n",
    "BROKER_LIST = [\"15.164.218.105:9091\", \"15.164.218.105:9092\", \"15.164.218.105:9093\"]\n",
    "TOPIC = \"transction\"\n",
    "\n",
    "def retry_with_backoff(max_retries: int = 5,\n",
    "                       initial_backoff: float = 1.0,\n",
    "                       max_backoff: float = 30.0):\n",
    "    \"\"\"\n",
    "    예외 발생 시 지수적 백오프를 사용하여 함수를 다시 시도하는 데코레이터입니다.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            retries = 0\n",
    "            backoff = initial_backoff\n",
    "            while True:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    retries += 1\n",
    "                    if retries > max_retries:\n",
    "                        print(f\"{func.__name__} failed after {retries} attempts: {e}\")\n",
    "                        raise\n",
    "                    print(f\"{func.__name__} error: {e}, retry {retries}/{max_retries} in {backoff}s\")\n",
    "                    time.sleep(backoff)\n",
    "                    backoff = min(backoff * 2, max_backoff)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "        \n",
    "class KafkaDataProducerService:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        API Data to Kafka\n",
    "    Params:\n",
    "        - topic_name (str, Required) : Topic명\n",
    "        - brokers (List[str], Required) : Broker 목록\n",
    "        - retries (Optional[int]) : 재시도 횟수\n",
    "    \"\"\"\n",
    "    def __init__(self, topic, brokers, retries = 3):\n",
    "        self.topic = topic\n",
    "        self.brokers = brokers\n",
    "        self.retries = retries\n",
    "        \n",
    "        self.producer = self._create_producer()\n",
    "\n",
    "    @retry_with_backoff(max_retries = int(os.getenv(\"RETRY_MAX\", 6)), \n",
    "                        initial_backoff = float(os.getenv(\"RETRY_INITIAL_BACKOFF\", 1.0)), \n",
    "                        max_backoff = float(os.getenv(\"RETRY_MAX_BACKOFF\", 30.0)))\n",
    "    def _create_producer(self) -> KafkaProducer:\n",
    "        return KafkaProducer(\n",
    "            bootstrap_servers = self.brokers,\n",
    "            retries = self.retries,\n",
    "            value_serializer=lambda v: json.dumps(v).encode(\"utf-8\"),\n",
    "            request_timeout_ms=30000\n",
    "        )\n",
    "\n",
    "    def publish(self, messages):\n",
    "        for messgae in messages:\n",
    "            try:\n",
    "                future = self.producer.send(self.topic, messgae)\n",
    "                metadata = future.get(timeout=10)\n",
    "                print(f\"Publish to {self.topic} partition = {metadata.partition} offset = {metadata.offset}\")\n",
    "            except KafkaError as e:\n",
    "                print(f\"Kafka publish error : {e}\")\n",
    "        try:\n",
    "            self.producer.flush()\n",
    "        except KafkaError as e:\n",
    "            print(f\"Error flushing producer: {e}\")\n",
    "\n",
    "    def close(self):\n",
    "        try:\n",
    "            self.producer.close()\n",
    "            print(\"Kafka producer closed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error closing producer: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    service = KafkaDataProducerService(TOPIC, BROKER_LIST)\n",
    "    try:\n",
    "        tickers = Api.get_tickers()\n",
    "        if not tickers:\n",
    "            print(\"No tickers retrived; aborting\")\n",
    "        else:\n",
    "            messages = [Api.get_price(t) for t in tickers]\n",
    "            service.publish(messages)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in data publishing workflow: {e}\")\n",
    "    finally:\n",
    "        service.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f42058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
